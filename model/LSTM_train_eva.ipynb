{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3702,
     "status": "ok",
     "timestamp": 1715957222952,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "EBuUd8odeVOa",
    "outputId": "f8cd2403-91d3-4220-8ca4-86cdf60f4cf6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1715957222953,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "EVhG8QFXksCj",
    "outputId": "a93f5f40-61ed-402c-9ad6-43af9c4994b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/MyDrive/FIT3162')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1715957222953,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "WZB2TcL-eR_v",
    "outputId": "13761565-5966-4579-ac1b-4b973bba30e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mbackup\u001b[0m/     \u001b[01;34mLSTM_Basic_Model\u001b[0m/     \u001b[01;34mSGDRegressor\u001b[0m/  WI24_Hugging_Face_Transformers_Tutorial.ipynb\n",
      "\u001b[01;34mdata\u001b[0m/       LSTM_train_eva.ipynb  \u001b[01;34mSubmission\u001b[0m/\n",
      "\u001b[01;34mFP-Growth\u001b[0m/  LSTNET.ipynb          \u001b[01;34mSVR\u001b[0m/\n",
      "\u001b[01;34mLSTM\u001b[0m/       \u001b[01;34mmodel\u001b[0m/                \u001b[01;34mTFTModel\u001b[0m/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1715957222954,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "jQa93wfnzKUr",
    "outputId": "773b7f14-ccf9-4f27-d359-f93384240f2a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Try on Proshphet model from facebook to train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1715957222954,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "A8_lh-oc38Or",
    "outputId": "c9215b8e-ebb9-438e-a5a5-dbcf7cde2c39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9565,
     "status": "ok",
     "timestamp": 1715957232507,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "3lvPr43V_Mf5",
    "outputId": "71383779-0f87-4fb7-c9e0-999a0c93146e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyts in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.4.2)\n",
      "Requirement already satisfied: numba>=0.55.2 in /usr/local/lib/python3.10/dist-packages (from pyts) (0.58.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.2->pyts) (0.41.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->pyts) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pyts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5NVhsKinOPF"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1715957232508,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "ZfMkZimorAIb",
    "outputId": "b7dc2536-4c5c-4e4d-fa71-09547103d859"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Preprocess the dataset\n",
    "\n",
    "#Preprocess the data\n",
    "import torch\n",
    "import numpy as np;\n",
    "from torch.autograd import Variable\n",
    "from pyts.approximation import SymbolicAggregateApproximation\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "def normalise_sd(x):\n",
    "        #x.std() standard deviation: measure of the spread or variability of the\n",
    "        #data. The standard deviation is computed by taking the square root of the\n",
    "        #average squared deviation from the mean\n",
    "        #This factor adjusts the standard deviation to account for the fact that\n",
    "        #the sample mean is not the same as the population mean, and it is based\n",
    "        #on the degrees of freedom of the sample, which is one less than the sample size\n",
    "  #Bessel's correction, adjust the sd by mulpliying with square of (n-1)/n\n",
    "  #important when sample size is small -> provide better estimate of the population sd\n",
    "  #correction makes the sd slighly larger as compensating the fact\n",
    "  #that sample variance typically understimate of the population variance for small sample\n",
    "  return x.std() * np.sqrt((len(x) - 1)/len(x))\n",
    "\n",
    "class Data_util(object):\n",
    "   # train and valid is the ratio of training set and validation set. test = 1 - train - valid\n",
    "                                                #ntp: next token prediciton\n",
    "                                                #re: rolling evaluation\n",
    "  def __init__(self, file_name, train, valid, cuda, ntp, re, normalise = 2):\n",
    "    self.cuda_is_available = cuda\n",
    "    self.re = re\n",
    "    self.ntp = ntp\n",
    "    data = open(file_name);\n",
    "    #load txt file to be file object\n",
    "    #separate dat by ,\n",
    "    self.rawdat = np.loadtxt(data,delimiter=',')\n",
    "    # perform arm on data\n",
    "    self._arm(5, 0.7, 0.7, 50)\n",
    "    self.dat = np.zeros(self.rawdat.shape)\n",
    "    self.n, self.m = self.dat.shape;\n",
    "    self.normalise = 2\n",
    "    self.scale = np.ones(self.m)\n",
    "    #_for private\n",
    "    self._normalised(normalise)\n",
    "                    #0.6 * whole dataset size -> number of rows to train\n",
    "                    #0.8 end index for the rows for valid\n",
    "    self._split(int(train * self.n), int((train+valid) * self.n), self.n)\n",
    "                  #tensor from numpy array\n",
    "    self.scale = torch.from_numpy(self.scale).float()\n",
    "                                  #reshape the dimension of the original data\n",
    "                                  #with row_count = test[1].size(0) and self.m =\n",
    "    tmp = self.test[1] * self.scale.expand(self.test[1].size(0), self.m)\n",
    "\n",
    "    if self.cuda_is_available:\n",
    "      self.scale = self.scale.cuda() # move scaling parameters into GPU from CPU\n",
    "                #wrap the tensor for pytorch to track the history of operations to th\n",
    "                #this scaling tensor for auto-diffentiation\n",
    "    self.scale = Variable(self.scale)\n",
    "    #self.rse = normal_std(tmp); calculates the root squared error (RSE) of the model output tmp\n",
    "    self.rse = normalise_sd(tmp)\n",
    "    #calculates the relative absolute error (RAE) of the model output tmp\n",
    "    self.rae = torch.mean(torch.abs(tmp - torch.mean(tmp)))\n",
    "\n",
    "  def _arm(self, n_bins, min_support, min_threshold, n_rules):\n",
    "    data = self.rawdat\n",
    "    df = pd.DataFrame(data)\n",
    "    scaler = MinMaxScaler()\n",
    "    norm_data = scaler.fit_transform(df)\n",
    "    sax = SymbolicAggregateApproximation(n_bins=n_bins, strategy='uniform')\n",
    "    sax_df = pd.DataFrame(sax.fit_transform(norm_data))\n",
    "    binary_sax_df = pd.get_dummies(sax_df)\n",
    "    frequent_itemsets = apriori(binary_sax_df, min_support=min_support, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=min_threshold)\n",
    "    rules = rules.sort_values(by=['zhangs_metric'], ascending=False).iloc[:n_rules, :]\n",
    "    unique_items = set()\n",
    "    for index, row in rules.iterrows():\n",
    "        unique_items.update([int(item[:-2]) for item in row['antecedents']])\n",
    "        unique_items.update([int(item[:-2]) for item in row['consequents']])\n",
    "    unique_items = list(unique_items)\n",
    "    df = df.iloc[:, unique_items]\n",
    "    self.rawdat = df.values\n",
    "\n",
    "  def _normalised(self, normalise):\n",
    "    #normalised by the max value of entire matrix\n",
    "    if (normalise == 0):\n",
    "      self.dat = self.rawdat\n",
    "    elif (normalise == 1):\n",
    "      self.dat = self.rawdat / np.max(self.rawdat)\n",
    "    elif (normalise == 2):\n",
    "      #normalised by the max value of each row\n",
    "      for i in range(self.m):\n",
    "        #list of scaling values for each of the data\n",
    "        self.scale[i] = np.max(np.abs(self.rawdat[:,1]))\n",
    "        #normalise the value in individual column based on the largest value in column\n",
    "        #some column largest values might be negative\n",
    "        self.dat[:,i] = self.rawdat[:,i]/np.max(np.abs(self.rawdat[:,i]))\n",
    "\n",
    "  def _split(self, train, valid, test):\n",
    "                        #leave for the self.re: rolling_evaluation (validation)\n",
    "                        #self.ntp: next few tokens prediction\n",
    "                                              #0.6\n",
    "      train_set = range(self.re+self.ntp-1, train);#save the front valus for re and ntp\n",
    "      valid_set = range(train, valid); #0.6 - 0.8\n",
    "      test_set = range(valid, self.n);#remaining for text 0.2, 0.8 - 1.0\n",
    "      #train dataset\n",
    "      self.train = self._batchify(train_set, self.ntp);\n",
    "      self.valid = self._batchify(valid_set, self.ntp);\n",
    "      self.test = self._batchify(test_set, self.ntp);\n",
    "\n",
    "  #self.train = self._batchify(train_set, self.ntp);\n",
    "  def _batchify(self, idx_set, ntp):#horizon for next prediciton\n",
    "  #number of samples in one batch\n",
    "    #index set for dataset (train_set if train_set passed)\n",
    "    #each dataset has a n\n",
    "    n = len(idx_set)  #rolling_evaluation , size of the input column\n",
    "    X = torch.zeros((n, self.re,self.m))\n",
    "    Y = torch.zeros((n,self.m))\n",
    "\n",
    "\n",
    "    for i in range(n):  #end: start of the next token prediction\n",
    "    #for each row/entry set the region for the training\n",
    "      #[train] + [rolling_evaluation]\n",
    "      end = idx_set[i] - self.ntp + 1 #save the last few token/value for next token prediciton\n",
    "      #start: start of rolling evaluation\n",
    "      start = end - self.re #save the values infront values save for self.ntp to do rolling_evalution\n",
    "      #slice the input data for training\n",
    "      #by slicing each sample/entry/row into X\n",
    "      #between start and end to be the training dataset\n",
    "\n",
    "      #create a PyTorch tensor 'X' with 5 batches, each containing a slice of 20 rows from 'data'\n",
    "      #X = torch.empty(5, 20, 10)  # Pre-initialize X with the desired shape\n",
    "      #X will contain 5 separate slices from data\n",
    "\n",
    "      #slice the many rows of data except for\n",
    "      X[i,:,:] = torch.from_numpy(self.dat[start:end, :])\n",
    "      #for batching multiple rows of data together to train from start to end\n",
    "      #his line is assigning a 2D slice of the numpy array self.dat to the i-th\n",
    "      # index in the first dimension of the tensor X\n",
    "      #start:end indicates a range of rows, so you’re selecting multiple rows and all columns within that range.\n",
    "      #This line is assigning a 1D slice (a single row) of the numpy array self.dat\n",
    "      #to the i-th index in the first dimension of the tensor Y\n",
    "      Y[i,:] = torch.from_numpy(self.dat[idx_set[i], :]);\n",
    "      #idx_set[i] is an index for a specific row, so you’re selecting just that row and all columns in it.\n",
    "      #The result is that Y[i,:] will be a 1D tensor with the same number of elements as there are columns in self.dat.\n",
    "\n",
    "\n",
    "    return [X,Y]\n",
    "\n",
    "    #train_loss = train(Data, x, y, model, criterion, optim, args.batch_size)\n",
    "    #data.get_batches(X,Y, batch_size, True):\n",
    "  def get_batches(self, inputs, targets, batch_size, shuffle=True):\n",
    "    #get_batches used in training loop to iterate over the generator to ge the batche of data\n",
    "    #for each training step\n",
    "    length = len(inputs)\n",
    "    if shuffle: #permutation to shuffle the whole row/entry, so different first value in en\n",
    "      #creates a tensor named index that contains a random permutation of\n",
    "      #integers from 0 to length-1. Then shuffle the valus according the random valus\n",
    "      index = torch.randperm(length)#randperm uses a Fisher-Yates shuffle algorithm to create a random permutation of numbers\n",
    "    else: #create a long type tensor with original arrangement\n",
    "      index = torch.LongTensor(range(length))\n",
    "    start_idx = 0\n",
    "    while (start_idx < length):\n",
    "      end_idx = min(length,start_idx + batch_size)\n",
    "      data_idx = index[start_idx:end_idx]\n",
    "      X = inputs[data_idx]\n",
    "      Y = targets[data_idx]\n",
    "      if (self.cuda_is_available):\n",
    "        X = X.cuda()\n",
    "        Y = Y.cuda()\n",
    "        #return multiple values in generator-level fashion\n",
    "        #Data.train[1] = Variable(X)\n",
    "      yield Variable(X), Variable(Y)\n",
    "      start_idx += batch_size\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4764,
     "status": "ok",
     "timestamp": 1715957237256,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "8zdxRu8Jbel7",
    "outputId": "57da3aa4-35d3-4812-e865-ccf1fde70804"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#python main.py --gpu 3 --horizon 24 --data data/electricity.txt --save save/elec.pt --output_fun Linear\n",
    "#args = parser.parse_args()\n",
    "#Data = Data_util(args.data, 0.6, 0.2, args.cuda, args.horizon, args.window, args.normalise);\n",
    "Data = Data_util('data/electricity.txt', 0.6, 0.2, False, 12, 24 * 7, 2);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1715957237257,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "tFiGZElHdKMs",
    "outputId": "7666c2d1-13c7-4252-db62-0d7d58fd8eeb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def evaluate(data, X, Y, model, evaluateL2, evaluateL1, batch_size):\n",
    "  model.eval()\n",
    "  total_loss = 0\n",
    "  total_loss_l1 = 0\n",
    "  n_samples = 0\n",
    "  predict = None\n",
    "  test = None\n",
    "\n",
    "  for X, Y in data.get_batches(X,Y, batch_size, False):\n",
    "    output = model(X)\n",
    "    #predict can be chanegd durring the for loop\n",
    "    if predict is None:\n",
    "      predict = output;\n",
    "      test = Y;\n",
    "    else:\n",
    "      predict = torch.cat((predict,output))\n",
    "      test = torch.cat((test, Y))\n",
    "\n",
    "    scale = data.scale.expand(output.size(0), data.m)\n",
    "    #computer L2 loss = mean squared error (MSE)\n",
    "    #.data[0] contain the loss value\n",
    "    #scale to bring back the value if they were normalised\n",
    "    # total_loss += evaluateL2(output * scale, Y * scale).data[0]\n",
    "    #.item() to get the loss value\n",
    "    total_loss += evaluateL2(output * scale, Y * scale).item()\n",
    "    total_loss_l1 += evaluateL1(output * scale, Y * scale).item()\n",
    "                #output.size(0) = batch_size * number of columns in the dataset\n",
    "    n_samples += (output.size(0) * data.m)\n",
    "  #rse: Root relative squared error: predictive accuracy of a model in statistics and machine learning\n",
    "  #   = mse/ population sd +-= (nomalised sample sd)\n",
    "  rse = math.sqrt(total_loss / n_samples)/data.rse\n",
    "  rae = (total_loss_l1 / n_samples)/data.rae\n",
    "\n",
    "  # converts a PyTorch tensor to a NumPy array\n",
    "  #safe way:\n",
    "  #predict = predict.detach().cpu().numpy()\n",
    "  # can lead to potential issues with the computation graph and gradient tracking.\n",
    "  predict = predict.data.cpu().numpy()\n",
    "  #make the numpy array to refer the memory locaiton of the tensor\n",
    "  #change to numpy array -. from tensor\n",
    "  #singma_p contains the sd of the prediciton for partical feature\n",
    "  #across all samples -. for understanding the variability of the model's prediction\n",
    "  #for each deature\n",
    "  #In a machine learning context, this operation is often performed after making\n",
    "  #predictions with a model to analyze the consistency of the predictions.\n",
    "  #A lower standard deviation indicates that the model’s predictions for that\n",
    "  #feature are more consistent, while a higher standard deviation indicates\n",
    "  #greater variability.\n",
    "  Ytest = test.data.cpu().numpy()\n",
    "  sd_p = predict.std(axis=0)\n",
    "  sd_g = Ytest.std(axis=0)\n",
    "  #calculate the mean for each column (across the rows)\n",
    "  #Ytest = np.array([[1, 4],\n",
    "                  # [2, 5],\n",
    "                  # [3, 6]])\n",
    "  #print(mean_g)  # Output: [2. 5.]\n",
    "  mean_p = predict.mean(axis=0)\n",
    "  mean_g = Ytest.mean(axis=0)\n",
    "  #True if the corresponding element in sigma_g is not equal to zero.\n",
    "  #filter out the columns/features with sd = 0  to avoid divison by 0 problem\n",
    "  #in subsequent correlation function\n",
    "  #output a boolean index array with true/false\n",
    "  #index: boolean array\n",
    "  index = (sd_g != 0)\n",
    "  #calculate the correlation for each column\n",
    "  correlation = ((predict - mean_p) * (Ytest - mean_g)).mean(axis = 0)/(sd_p * sd_g)\n",
    "  #correlation for the column that has index with true in boolean index array\n",
    "  correlation = (correlation[index]).mean()\n",
    "  return rse, rae, correlation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1715957237257,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "6MC1Zsm4BhiI",
    "outputId": "e0ec36a5-0235-4df3-e450-0560e201a570"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "#argparse to parse the input argument which take a path\n",
    "parser = argparse.ArgumentParser(description='Pytorch Time series forecasting')\n",
    "# parser.add_argument('--data', type = str, required=True, help='location of the data file')\n",
    "# parser.add_argument('--ntp', type=int, default=12)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "#only parse known arguments, and store unknown arguments in the unknown variable\n",
    "args, unknown = parser.parse_known_args()\n",
    "args.data = 'data/electricity.txt'\n",
    "args.window = 24 * 7\n",
    "args.hidRNN = 100\n",
    "args.hidCNN = 100\n",
    "args.hidSkip = 5\n",
    "args.CNN_kernel = 6\n",
    "args.skip = 24\n",
    "args.gpu = 1\n",
    "args.cuda = True\n",
    "args.highway_window = 24\n",
    "args.dropout = 0.2\n",
    "args.output_fun = 'sigmoid'\n",
    "args.model = 'LSTNet'\n",
    "args.batch_size = 128\n",
    "args.seed = 54321\n",
    "args.L1Loss = True\n",
    "args.optim = 'adam'\n",
    "args.lr = 0.01\n",
    "args.clip = 10\n",
    "args.epochs = 4\n",
    "args.save = 'model/model.pt' #pt: performace track\n",
    "args.horizon = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1715957237257,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "h8XaMMg36CWy",
    "outputId": "d5b37820-f64a-46b6-c982-f756ba4fa921"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class Gate(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Gate, self).__init__()\n",
    "        # Initialize weights and bias for the gate\n",
    "        self.W = nn.Parameter(torch.randn(output_size*2,output_size))\n",
    "        self.b = nn.Parameter(torch.zeros(output_size, 1))\n",
    "        # Bottleneck transformation layer [321, 128]\n",
    "        self.bottleneck = nn.Linear(input_size, output_size)\n",
    "        self.bn_concat = nn.Linear(input_size, output_size*2)\n",
    "\n",
    "    def forward(self, x_t, h_prev):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        x_t = x_t.to(device)\n",
    "        h_prev = h_prev.to(device)\n",
    "        #print(x_t.shape)\n",
    "        # Transform x_t to the correct size using the bottleneck layer\n",
    "        x_t_transformed = self.bottleneck(x_t)\n",
    "        #print(x_t_transformed.shape)\n",
    "        # Concatenate transformed input and previous hidden state along the feature dimension\n",
    "        concat = torch.cat((x_t_transformed.t(), h_prev), dim=1)\n",
    "        #print(concat.shape)\n",
    "        # Compute the gate's output\n",
    "        #torch.matmul = dot product\n",
    "\n",
    "        z = torch.matmul(concat,self.W) + self.b\n",
    "        gate_output = torch.sigmoid(z)\n",
    "\n",
    "        return gate_output\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class ForgetGate(Gate):\n",
    "  def __init__(self, input_size, output_size):\n",
    "    super().__init__(input_size, output_size)\n",
    "\n",
    "  def forward(self, x_t, h_prev):\n",
    "    f_t = super().forward(x_t, h_prev)\n",
    "    return f_t\n",
    "\n",
    "class InputGate(Gate):\n",
    "  def __init__(self, input_size, output_size):\n",
    "    super().__init__(input_size, output_size)\n",
    "\n",
    "    #Control mu embedding\n",
    "    self.w_C = nn.Parameter(torch.randn(output_size*2, output_size))\n",
    "    self.b_C = nn.Parameter(torch.zeros(output_size, 1))\n",
    "\n",
    "  def control_forward(self, x_t, h_prev):\n",
    "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "      #print(x_t.shape)\n",
    "      x_t_transformed = self.bottleneck(x_t).to(device)\n",
    "      #print(x_t_transformed.shape)\n",
    "      h_prev = h_prev.to(device)\n",
    "      concat = torch.cat((x_t_transformed, h_prev), dim=1)\n",
    "\n",
    "      # Use matmul for matrix multiplication\n",
    "      temp = torch.matmul(concat, self.w_C)\n",
    "      #print(temp.shape)\n",
    "      C_mu = torch.tanh(temp + self.b_C)\n",
    "      return C_mu\n",
    "\n",
    "\n",
    "  def forward(self,x_t, h_prev):\n",
    "    i_t = super().forward(x_t, h_prev)\n",
    "    C_t = self.control_forward(x_t, h_prev)\n",
    "    return i_t, C_t\n",
    "\n",
    "class OutputGate(Gate):\n",
    "  def __init__(self, input_size, output_size):\n",
    "    super().__init__(input_size, output_size)\n",
    "\n",
    "  def forward(self, x_t, h_prev):\n",
    "    o_t = super().forward(x_t, h_prev)\n",
    "    return o_t\n",
    "\n",
    "\n",
    "class LSTMCell(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super().__init__()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    # Bottleneck transformation layer\n",
    "    self.bottleneck = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "\n",
    "    #Initialisise gates\n",
    "    self.input_gate = InputGate(input_size, hidden_size)\n",
    "    self.forget_gate = ForgetGate(input_size, hidden_size)\n",
    "    self.output_gate = OutputGate(input_size, hidden_size)\n",
    "    self.cell_state = nn.Parameter(torch.zeros(hidden_size,1))\n",
    "\n",
    "  def forward(self, x_t, h_prev, c_prev):\n",
    "      # Move all tensors to the same device as the model\n",
    "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "      x_t, h_prev, c_prev = x_t.to(device), h_prev.to(device), c_prev.to(device)\n",
    "\n",
    "      i_t, c_mu = self.input_gate.forward(x_t, h_prev)\n",
    "      f_t = self.forget_gate.forward(x_t, h_prev)\n",
    "      o_t = self.output_gate.forward(x_t, h_prev)\n",
    "\n",
    "      #print(\"f_t\")\n",
    "      #print(f_t.shape)\n",
    "\n",
    "      #print(f_t.shape)\n",
    "      #print(c_prev.shape)\n",
    "      c_t = f_t * c_prev + i_t * c_mu\n",
    "\n",
    "      # Compute the current hidden state\n",
    "      h_t = o_t * torch.tanh(c_t)\n",
    "\n",
    "      return h_t, c_t\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size=128):\n",
    "    # = super(LSTM,self).__init__()\n",
    "\n",
    "    super().__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.lstm_cell = LSTMCell(input_size, hidden_size)\n",
    "    self.inver_bottleneck = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "  def forward(self, batch_size, input_sequence):\n",
    "      # Initialize hidden state and cell state for each sequence in the batch\n",
    "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "      h_t = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "      c_t = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "\n",
    "      for t in range(len(input_sequence)):\n",
    "          x_t = input_sequence[:, t, :].to(device)\n",
    "          #print(x_t.shape)\n",
    "          h_t, c_t = self.lstm_cell(x_t, h_t, c_t)\n",
    "\n",
    "      return h_t, self.inver_bottleneck(c_t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1715957237258,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "c1DRZyeVAj5w",
    "outputId": "4c9b25a1-c537-493a-9ba3-77649263bac1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np;\n",
    "import importlib\n",
    "\n",
    "def train(data, X, Y, model, criterion, optim, batch_size):\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  #set model to training mode\n",
    "  model.train()\n",
    "  total_loss = 0\n",
    "  n_samples = 0\n",
    "  for X, Y in data.get_batches(X,Y, batch_size, True):\n",
    "    #reset the model parameters before training\n",
    "    model.zero_grad()\n",
    "    output = model(batch_size,X)\n",
    "    output = output[1]\n",
    "    #expnad the scaling matrix into the of output\n",
    "    #.size() method on the output tensor to get its size.\n",
    "    #The arguments (0, data.m) indicate that you want to expand data.scale to\n",
    "    #have the same size as the first dimension of output and the size\n",
    "    #of data.m for the second dimension.\n",
    "\n",
    "    #By expanding data.scale, you can ensure that it has the same size as output\n",
    "    #for broadcasting purposes, which is often needed in operations like element-\n",
    "    #wise multiplication or addition.\n",
    "    data.scale = data.scale\n",
    "    scale = data.scale.expand(output.shape[0], data.m)\n",
    "    #print(scale.shape)\n",
    "    #criterion: loss function measure difference between the predicted outputs and the true values.\n",
    "    Y = Y\n",
    "    #print(output.shape)\n",
    "    loss = criterion(output*scale, Y * scale)\n",
    "    loss.backward()\n",
    "    #gradient clipping to prevent gradient explosion or diminishing\n",
    "    # grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "    #step function to call the model to update the parameters based on the computed gradients.\n",
    "    grad_norm = optim.step()\n",
    "    total_loss += loss.item() ## Extract the loss value as a Python float\n",
    "    #number of samples = first dimension size of the output * dataset second dimension\n",
    "    #calculates the total number of elements in the current batch by multiplying the\n",
    "    #batch size by the number of features or time steps. This product is then added\n",
    "    #to the n_samples variable, which accumulates the total number of elements processed\n",
    "    #over multiple batches\n",
    "    n_samples += (output.size(0) * data.m)\n",
    "  return total_loss/n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 121958,
     "status": "ok",
     "timestamp": 1715960353576,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "rSzpU6yucMPj",
    "outputId": "1ca1bb94-fbb4-401b-d6d5-64a62a38e4e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training\n",
      "115\n",
      "Epoch 1, Loss: 0.5913922786712646\n",
      "115\n",
      "Epoch 2, Loss: 0.09057506918907166\n",
      "13\n",
      "Validation: Epoch 2, Loss: 0.042657215148210526\n",
      "115\n",
      "Epoch 3, Loss: 0.03669028729200363\n",
      "115\n",
      "Epoch 4, Loss: 0.025276990607380867\n",
      "13\n",
      "Validation: Epoch 4, Loss: 0.027647553011775017\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "##Optimasation\n",
    "import math\n",
    "import torch.optim as optim\n",
    "\n",
    "class Optim(object):\n",
    "  def _makeOptimizer(self):\n",
    "    if self.method == 'sgd':\n",
    "      self.optimizer = optim.SGD(self.params, lr=self.lr)\n",
    "    elif self.method == 'adagrad':\n",
    "      self.optimizer = optim.Adagrad(self.params, lr=self.lr)\n",
    "    elif self.method == 'adadelta':\n",
    "      self.optimizer = optim.Adadelta(self.params, lr=self.lr)\n",
    "    elif self.method == 'adam':\n",
    "            self.optimizer = optim.Adam(self.params, lr=self.lr)\n",
    "    else:\n",
    "          raise RuntimeError(\"Invalid optim method: \" + self.method)\n",
    "\n",
    "  def __init__(self, params, method, lr, max_grad_norm, lr_decay=1, start_decay_at=None):\n",
    "    self.params = list(params) #params may be a generator\n",
    "    self.lr = lr\n",
    "    #max_grad_norm maximum normalise gradient allowed before clipping\n",
    "    self.max_grad_norm = max_grad_norm\n",
    "    self.method = method\n",
    "    self.lr_decay = lr_decay\n",
    "    self.start_decay_at = start_decay_at\n",
    "    self.start_decay = False\n",
    "\n",
    "    self._makeOptimizer()\n",
    "\n",
    "  def step(self):\n",
    "    #computer gradients norm\n",
    "    grad_norm = 0\n",
    "    for param in self.params:\n",
    "      #etrieves the gradient data for a parameter of the neural network\n",
    "      #norm() squares the L2 norm (Euclidean norm) of the gradient tensor.\n",
    "      grad_norm += math.pow(param.grad.data.norm(),2)#since 2\n",
    "      #accumulates the sum of the squared norms of all parameters’ gradients.\n",
    "    grad_norm = math.sqrt(grad_norm)\n",
    "    #squre root to get the overal L2 norm\n",
    "\n",
    "    if grad_norm > 0:\n",
    "      shrinkage = self.max_grad_norm / grad_norm\n",
    "    else:    #1.: float-point number\n",
    "      shrinkage = 1.\n",
    "\n",
    "    for param in self.params:\n",
    "      #if meet the threshold, apply gradient cliping\n",
    "      if shrinkage < 1:\n",
    "        #apply gradient clipping for each parameter's gradient\n",
    "        param.grad.data.mul_(shrinkage)\n",
    "\n",
    "    self.optimizer.step()\n",
    "    return grad_norm\n",
    "\n",
    "  #decay learning rate if not improve on val perf\n",
    "  #or change start_decay_limit to true\n",
    "  def upadateLearningRate(self, ppl, epoch):\n",
    "      #decide which epoch to start decaying the learning rate\n",
    "    if self.start_decay_at is not None and epoch >= self.start_decay_at:\n",
    "      self.start_decay = True\n",
    "      # stores the perplexity value from the last evaluation\n",
    "      #ppl: Perplexity (PPL): It is a metric used to evaluate language models.\n",
    "      #It’s defined as the exponentiated average negative log-likelihood of a sequence. The lower the perplexity, the better the model is at predicting the sequence1.\n",
    "    if self.last_ppl is not None and ppl > self.last_ppl:\n",
    "      self.start_decay = True\n",
    "\n",
    "    if self.start_decay:\n",
    "      self.lr = self.lr * self.lr_decay\n",
    "      print(\"Decaying learning rate to %g\" % self.lr)\n",
    "\n",
    "\n",
    "    #only decay for one epoch\n",
    "    self.start_decay = False\n",
    "\n",
    "    self.last_ppl = ppl\n",
    "\n",
    "    self._makeOptimizer()\n",
    "# model = Model(args,Data)\n",
    "# optim = Optim(\n",
    "#     model.parameters(), args.optim, args.lr, args.clip,\n",
    "# )\n",
    "\n",
    "#LSTM\n",
    "model = LSTM((len(Data.rawdat[0])))\n",
    "optim = Optim(\n",
    "    model.parameters(), args.optim, args.lr, args.clip,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, data, args, train_func, evaluate_func, optim):\n",
    "  best_val = 10000000;\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  model.to(device)\n",
    "\n",
    "  #move everything to the same device - GPU\n",
    "  if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    #moving X to GPU\n",
    "    Data.train[0] = Data.train[0].cuda()\n",
    "    Data.train[1].cuda()\n",
    "\n",
    "    if not args.cuda:\n",
    "      print(\"WARNING, have gpu, should run with --cuda\")\n",
    "    else:\n",
    "      torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "  if args.L1Loss:\n",
    "    #L1 loss = MAE (Mean Absolute Error) loss  mean of absolute difference\n",
    "    #between target value and predictions\n",
    "\n",
    "    # criterion = nn.L1Loss(size_average=False)\n",
    "    #average = loss -> losses are summed\n",
    "    criterion = nn.L1Loss(reduction='sum')\n",
    "\n",
    "\n",
    "  else:\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "\n",
    "    #set up L2 loss - MSE loss during validation or testing\n",
    "  evaluateL2 = nn.MSELoss(reduction='sum')\n",
    "  evaluateL1 = nn.L1Loss(reduction='sum')\n",
    "\n",
    "  #.cuda(): This method transfers the loss function to the GPU.\n",
    "  if args.cuda:\n",
    "    criterion = criterion.cuda()\n",
    "    evaluateL1 = evaluateL1.cuda()\n",
    "    evaluateL2 = evaluateL2.cuda()\n",
    "\n",
    "  # Define loss function and optimizer\n",
    "  criterion = nn.MSELoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "  # At any point you can hit Ctrl + C to break out of training early.\n",
    "  try:\n",
    "      print('begin training');\n",
    "      #'Namespace' object has no attribute 'epochs' = args.epoch is not defined\n",
    "      model = model.to(device)\n",
    "      for epoch in range(1, args.epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        X = Data.train[0].to(device)\n",
    "        Y = Data.train[1].to(device)\n",
    "\n",
    "\n",
    "        for x, y in data.get_batches(X,Y, args.batch_size, True):\n",
    "          padding_size =  args.batch_size - len(x)\n",
    "          y_ori_len = len(y)\n",
    "          if y_ori_len != 128:\n",
    "              print(y_ori_len)\n",
    "\n",
    "          if padding_size > 0:\n",
    "            #overlapping batch_size, sequence length, feature_size/sensor num\n",
    "\n",
    "            #print(input_sequence.size(0)) [128, 168, 321]\n",
    "\n",
    "\n",
    "            # Create a tensor of zeros for padding\n",
    "\n",
    "            x_padding = torch.zeros(padding_size, x.size(1), x.size(2)).to(device)\n",
    "            y_padding = torch.zeros(padding_size, x.size(2)).to(device)\n",
    "            # print(padding.size())\n",
    "            # Concatenate the padding to the x\n",
    "            x = torch.cat((x, x_padding), dim=0)\n",
    "            # Concatenate the padding to the x\n",
    "            y = torch.cat((y, y_padding), dim=0)\n",
    "          #reset the model parameters before training\n",
    "          model.zero_grad()\n",
    "          hidden_state, output = model(args.batch_size,x)\n",
    "\n",
    "          #remove padding values/trailing zero\n",
    "          #avoid change to loss\n",
    "\n",
    "          output = output[:y_ori_len]\n",
    "          y = y[:y_ori_len]\n",
    "          #print(len(y))\n",
    "\n",
    "          loss = criterion(output, y)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "\n",
    "        if epoch % 2 == 0:\n",
    "          X_val = Data.valid[0].to(device)\n",
    "          Y_val = Data.valid[1].to(device)\n",
    "          for x_val, y_val in data.get_batches(X_val,Y_val, args.batch_size, True):\n",
    "            y_ori_len = len(y_val)\n",
    "\n",
    "            if y_ori_len != 128:\n",
    "              print(y_ori_len)\n",
    "            val_padding_size =  args.batch_size - len(x_val)\n",
    "            if val_padding_size > 0:\n",
    "\n",
    "                xval_padding = torch.zeros(val_padding_size, x_val.size(1), x_val.size(2)).to(device)\n",
    "                yval_padding = torch.zeros(val_padding_size, x_val.size(2)).to(device)\n",
    "                # print(padding.size())\n",
    "                # Concatenate the padding to the x\n",
    "                x_val = torch.cat((x_val, xval_padding), dim=0)\n",
    "                # Concatenate the padding to the x\n",
    "                y_val = torch.cat((y_val, yval_padding), dim=0)\n",
    "\n",
    "            hidden_state, valid_output = model(args.batch_size,x_val)\n",
    "            valid_output = valid_output[:y_ori_len]\n",
    "            y_val = y_val[:y_ori_len]\n",
    "            val_loss = criterion(valid_output,y_val)\n",
    "\n",
    "            if val_loss.item() < best_val:\n",
    "              with open(args.save, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "              best_val = val_loss.item()\n",
    "          #torch.device('cuda:0') for the first GPU or torch.device('cpu') for the CPU1.\n",
    "          #then .to(device) would go to either CPU or GPU\n",
    "          #.cude(1) go to first GPU\n",
    "          # model.to('cuda')\n",
    "\n",
    "          print(f\"Validation: Epoch {epoch}, Loss: {val_loss.item()}\")\n",
    "          if val_loss.item() < best_val:\n",
    "            with open(args.save, 'wb') as f:\n",
    "              torch.save(model, f)\n",
    "            best_val = val_loss.item()\n",
    "        # if epoch % 5 == 0:\n",
    "        #   #torch.device('cuda:0') for the first GPU or torch.device('cpu') for the CPU1.\n",
    "        #   #then .to(device) would go to either CPU or GPU\n",
    "        #   #.cude(1) go to first GPU\n",
    "        #   # model.to('cuda')\n",
    "        #   test_acc, test_rae, test_corr  = evaluate(Data, x_test, y_test, model, evaluateL2, evaluateL1, args.batch_size);\n",
    "        #   print (\"test rse {:5.4f} | test rae {:5.4f} | test corr {:5.4f}\".format(test_acc, test_rae, test_corr))\n",
    "\n",
    "  except KeyboardInterrupt:\n",
    "      print('-' * 89)\n",
    "      print('Exiting from training early')\n",
    "\n",
    "\n",
    "  # test_acc, test_rae, test_corr  = evaluate(Data, x_test, y_test, model, evaluateL2, evaluateL1, args.batch_size);\n",
    "  # print (\"test rse {:5.4f} | test rae {:5.4f} | test corr {:5.4f}\".format(test_acc, test_rae, test_corr))\n",
    "\n",
    "\n",
    "train_and_evaluate(model, Data, args, train, evaluate, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1715960413423,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "DZdCCpbbDR1i",
    "outputId": "242f18a6-0117-4791-f260-4c92731af897"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025670342\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "def model_test(data,X,Y):\n",
    "  try:\n",
    "    count = 0\n",
    "    total_loss = 0\n",
    "    for x, y in data.get_batches(X,Y, args.batch_size, True):\n",
    "      y_ori_len = len(y)\n",
    "      with torch.no_grad():\n",
    "        if len(x) < args.batch_size:\n",
    "          #overlapping batch_size, sequence length, feature_size/sensor num\n",
    "\n",
    "          #print(input_sequence.size(0)) [128, 168, 321]\n",
    "\n",
    "          padding_size =  args.batch_size - len(x)\n",
    "          # Create a tensor of zeros for padding\n",
    "          device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "          x_padding = torch.zeros(padding_size, x.size(1), x.size(2)).to(device)\n",
    "          y_padding = torch.zeros(padding_size, x.size(2)).to(device)\n",
    "          # print(padding.size())\n",
    "          # Concatenate the padding to the x\n",
    "          x = torch.cat((x, x_padding), dim=0)\n",
    "          # Concatenate the padding to the x\n",
    "          y = torch.cat((y, y_padding), dim=0)\n",
    "          hidden_state, output = model(args.batch_size,x)\n",
    "\n",
    "          loss = criterion(output[:y_ori_len], y[:y_ori_len])\n",
    "          lost_in_batch = loss * y_ori_len\n",
    "          total_loss += lost_in_batch\n",
    "          count += y_ori_len\n",
    "\n",
    "    overal_loss = total_loss/count\n",
    "    return overal_loss\n",
    "\n",
    "  except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "\n",
    "with open(args.save, 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    X = Data.test[0].to(device)\n",
    "    Y = Data.test[1].to(device)\n",
    "\n",
    "    test_loss = model_test(Data,X,Y)\n",
    "    test_loss = test_loss.cpu()\n",
    "    test_loss = test_loss.numpy()\n",
    "    print(test_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1715960511089,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "WFK5e5i2DMjj",
    "outputId": "666b2729-0538-43fd-90ca-c3c9660d8fc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.04160048e-01  3.11262399e-01  5.37600107e-02  1.40088528e-01\n",
      "  -1.57865137e-03  1.97799340e-01  1.33452326e-01  2.73401961e-02\n",
      "   6.37714118e-02  1.44009173e-01]\n",
      " [ 8.61622095e-02  4.20505255e-01  4.97399122e-02  3.10947001e-01\n",
      "   1.07552633e-02  2.62633950e-01  1.47205144e-01  1.16594315e-01\n",
      "   1.37191728e-01  1.58644170e-01]\n",
      " [ 1.19487792e-01  2.83847988e-01  3.98674309e-02  8.60739276e-02\n",
      "  -1.88080035e-03  1.82131737e-01  1.06972896e-01  4.54132780e-02\n",
      "   8.64632428e-02  1.85222194e-01]\n",
      " [ 1.11486897e-01  3.08792859e-01 -2.47731656e-02  1.70766428e-01\n",
      "  -1.08106527e-02  1.76557735e-01  1.67766184e-01  5.29054925e-02\n",
      "   1.16678998e-01  1.05810024e-01]\n",
      " [ 1.09779075e-01  3.28198165e-01  3.46117727e-02  6.38946444e-02\n",
      "   3.98063753e-03  2.09127083e-01  1.43359840e-01  7.23321289e-02\n",
      "   9.98080671e-02  2.85948068e-02]\n",
      " [ 1.32794484e-01  2.94753700e-01  8.18605199e-02  2.22182661e-01\n",
      "  -8.36614706e-03  1.97851568e-01  1.05793774e-02  3.23504247e-02\n",
      "   1.34841800e-01 -2.36258134e-02]\n",
      " [ 1.75762385e-01  4.17278498e-01  1.21794976e-02  1.90865785e-01\n",
      "  -3.44846584e-03  2.40907267e-01  3.03014591e-02  7.97521025e-02\n",
      "   1.00905120e-01 -6.95747063e-02]\n",
      " [ 1.48213878e-01  5.52527249e-01  8.51858258e-02  3.43484581e-01\n",
      "   5.09835407e-03  2.59128302e-01  2.00336903e-01  6.34224266e-02\n",
      "   1.55783892e-01 -3.98453996e-02]\n",
      " [ 1.25210807e-01  3.05712342e-01  3.32206972e-02  1.76610962e-01\n",
      "   2.01474614e-02  1.61388740e-01  1.74482971e-01  6.13060482e-02\n",
      "   5.42201251e-02  1.35502100e-01]\n",
      " [ 9.55275446e-02  2.96447277e-01  3.08688898e-02  5.67688681e-02\n",
      "  -5.10375947e-04  1.69082418e-01  1.34724438e-01  6.71617389e-02\n",
      "   7.88125396e-02  5.14194295e-02]\n",
      " [ 1.92706615e-01  3.76333863e-01  3.63246538e-02  1.07633948e-01\n",
      "   1.01649035e-02  2.48344019e-01  1.18992753e-01  8.07442218e-02\n",
      "   1.16310388e-01  1.67989314e-01]\n",
      " [ 7.52924010e-02  3.25660110e-01  3.34610045e-03  1.68562979e-01\n",
      "  -2.72411872e-02  1.95112407e-01  7.01855719e-02  7.04739392e-02\n",
      "   7.80772567e-02 -6.27564564e-02]\n",
      " [ 1.52179033e-01  3.35511565e-01 -1.10941529e-02  1.40934289e-01\n",
      "   4.80907783e-03  2.14549378e-01  1.12989984e-01  7.53764808e-02\n",
      "   1.00721166e-01  5.42176664e-02]]\n",
      "0.10416005\n",
      "0.3112624\n",
      "0.05376001\n",
      "0.14008853\n",
      "-0.0015786514\n",
      "0.19779934\n",
      "0.13345233\n",
      "0.027340196\n",
      "0.06377141\n",
      "0.14400917\n",
      "0.10416005\n",
      "0.3112624\n",
      "0.05376001\n",
      "0.14008853\n",
      "-0.0015786514\n",
      "0.19779934\n",
      "0.13345233\n",
      "0.027340196\n",
      "0.06377141\n",
      "0.14400917\n",
      "0.10416005\n",
      "0.3112624\n",
      "0.05376001\n",
      "0.14008853\n",
      "-0.0015786514\n",
      "0.19779934\n",
      "0.13345233\n",
      "0.027340196\n",
      "0.06377141\n",
      "0.14400917\n",
      "0.10416005\n",
      "0.3112624\n",
      "0.05376001\n",
      "0.14008853\n",
      "-0.0015786514\n",
      "0.19779934\n",
      "0.13345233\n",
      "0.027340196\n",
      "0.06377141\n",
      "0.14400917\n",
      "0.10416005\n",
      "0.3112624\n",
      "0.05376001\n",
      "0.14008853\n",
      "-0.0015786514\n",
      "0.19779934\n",
      "0.13345233\n",
      "0.027340196\n",
      "0.06377141\n",
      "0.14400917\n",
      "0.10416005\n",
      "0.3112624\n",
      "0.05376001\n",
      "0.14008853\n",
      "-0.0015786514\n",
      "0.19779934\n",
      "0.13345233\n",
      "0.027340196\n",
      "0.06377141\n",
      "0.14400917\n",
      "0.10416005\n",
      "0.3112624\n",
      "0.05376001\n",
      "0.14008853\n",
      "-0.0015786514\n",
      "0.19779934\n",
      "0.13345233\n",
      "0.027340196\n",
      "0.06377141\n",
      "0.14400917\n",
      "0.10416005\n",
      "0.3112624\n",
      "0.05376001\n",
      "0.14008853\n",
      "-0.0015786514\n",
      "0.19779934\n",
      "0.13345233\n",
      "0.027340196\n",
      "0.06377141\n",
      "0.14400917\n",
      "0.10416005\n",
      "0.3112624\n",
      "0.05376001\n",
      "0.14008853\n",
      "-0.0015786514\n",
      "0.19779934\n",
      "0.13345233\n",
      "0.027340196\n",
      "0.06377141\n",
      "0.14400917\n",
      "0.10416005\n",
      "0.3112624\n",
      "0.05376001\n",
      "0.14008853\n",
      "-0.0015786514\n",
      "0.19779934\n",
      "0.13345233\n",
      "0.027340196\n",
      "0.06377141\n",
      "0.14400917\n",
      "0.10416005\n",
      "0.3112624\n",
      "0.05376001\n",
      "0.14008853\n",
      "-0.0015786514\n",
      "0.19779934\n",
      "0.13345233\n",
      "0.027340196\n",
      "0.06377141\n",
      "0.14400917\n",
      "0.10416005\n",
      "0.3112624\n",
      "0.05376001\n",
      "0.14008853\n",
      "-0.0015786514\n",
      "0.19779934\n",
      "0.13345233\n",
      "0.027340196\n",
      "0.06377141\n",
      "0.14400917\n",
      "0.10416005\n",
      "0.3112624\n",
      "0.05376001\n",
      "0.14008853\n",
      "-0.0015786514\n",
      "0.19779934\n",
      "0.13345233\n",
      "0.027340196\n",
      "0.06377141\n",
      "0.14400917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "def model_pred(data,X,Y):\n",
    "  try:\n",
    "    for x, y in data.get_batches(X,Y, args.batch_size, True):\n",
    "      with torch.no_grad():\n",
    "        y_ori_len = len(y)\n",
    "        if len(x) < args.batch_size:\n",
    "          #overlapping batch_size, sequence length, feature_size/sensor num\n",
    "\n",
    "          #print(input_sequence.size(0)) [128, 168, 321]\n",
    "\n",
    "          padding_size =  args.batch_size - len(x)\n",
    "          # Create a tensor of zeros for padding\n",
    "          device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "          x_padding = torch.zeros(padding_size, x.size(1), x.size(2)).to(device)\n",
    "          y_padding = torch.zeros(padding_size, x.size(2)).to(device)\n",
    "          # print(padding.size())\n",
    "          # Concatenate the padding to the x\n",
    "          x = torch.cat((x, x_padding), dim=0)\n",
    "          # Concatenate the padding to the x\n",
    "          y = torch.cat((y, y_padding), dim=0)\n",
    "          hidden_state, output = model(args.batch_size,x)\n",
    "          output = output[:y_ori_len]\n",
    "          #print(loss)\n",
    "          return hidden_state, output\n",
    "  except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "# Prediction\n",
    "# Load the best saved model.\n",
    "#output = None\n",
    "with open(args.save, 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    X = Data.test[0].to(device)\n",
    "    Y = Data.test[1].to(device)\n",
    "\n",
    "    hidden_state, output = model_pred(Data,X,Y)\n",
    "    output = output.cpu()\n",
    "    output = output.numpy()\n",
    "    print(output)\n",
    "\n",
    "    for i in range(len(output)):\n",
    "      for j in range(len(output[0])):\n",
    "        print(output[0][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1715957368532,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "jmHm19r9CrzT",
    "outputId": "8bd9b523-2cab-4c33-bf38-b8c15435726c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0259, device='cuda:0')\n",
      "[[ 0.10799022  0.4846455  -0.03865607 ...  0.14996779  0.20249039\n",
      "   0.18613245]\n",
      " [ 0.12396899  0.31155878  0.02285029 ...  0.08290128  0.08093178\n",
      "   0.21449259]\n",
      " [ 0.14538488  0.37113127  0.02701712 ...  0.04306798  0.09603888\n",
      "  -0.04584998]\n",
      " ...\n",
      " [ 0.06632088  0.3504464   0.0076936  ...  0.04886483  0.07113312\n",
      "   0.024163  ]\n",
      " [ 0.02928135  0.35948998 -0.01031119 ...  0.04650842  0.07564512\n",
      "   0.00478652]\n",
      " [ 0.1183884   0.34737423  0.06375515 ...  0.1106619   0.10203454\n",
      "   0.13310702]]\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n",
      "0.10799022\n",
      "0.4846455\n",
      "-0.03865607\n",
      "0.40295196\n",
      "0.022068465\n",
      "0.27124316\n",
      "0.182529\n",
      "0.14996779\n",
      "0.20249039\n",
      "0.18613245\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18424,
     "status": "ok",
     "timestamp": 1716020181836,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "3j7W8BUhxabp",
    "outputId": "f298beb2-5dc4-4d39-cc45-fb068743360c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/FIT3162')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1716020208967,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "_eAzYFdJxkef",
    "outputId": "2b7f76af-cb0b-4f3b-e424-b9f16d3917ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/FIT3162\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1716020217979,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "A9ZUGA2oxnE6",
    "outputId": "98feb26e-9f2b-4c1e-986c-c96f70f19795"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[0m\u001b[01;34mbackup\u001b[0m/            'LSTM_train_eva (1).ipynb'   \u001b[01;34mSVR\u001b[0m/\n",
      " \u001b[01;34mdata\u001b[0m/               LSTNET.ipynb                \u001b[01;34mTFTModel\u001b[0m/\n",
      " \u001b[01;34mFP-Growth\u001b[0m/          \u001b[01;34mmodel\u001b[0m/                      WI24_Hugging_Face_Transformers_Tutorial.ipynb\n",
      " \u001b[01;34mLSTM\u001b[0m/               \u001b[01;34mSGDRegressor\u001b[0m/\n",
      " \u001b[01;34mLSTM_Basic_Model\u001b[0m/   \u001b[01;34mSubmission\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1926,
     "status": "ok",
     "timestamp": 1716020284904,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "4ozdBicExAzc",
    "outputId": "480a55f7-0e4d-4d85-c315-988ba1977c22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook LSTM_train_eva (1).ipynb to script\n",
      "[NbConvertApp] Writing 31596 bytes to LSTM_train_eva (1).txt\n"
     ]
    }
   ],
   "source": [
    "                                            #wildcard to change all version into python code\n",
    "!jupyter nbconvert --to script LSTM_train_eva*.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1716020345755,
     "user": {
      "displayName": "Dizhen Liang",
      "userId": "06557023756950998584"
     },
     "user_tz": -480
    },
    "id": "EQ4cG7gmyG2W"
   },
   "outputs": [],
   "source": [
    "#Great! It looks like your Jupyter Notebook LSTM_train_eva (1).ipynb has been successfully converted to a script. However, the output file has a .txt extension instead of .py. This is just a minor issue, as the content is still Python code.\n",
    "\n",
    "# To ensure the file is recognized as a Python script by editors and IDEs, you can simply rename the file to have a .py extension. You can do this by running the following command in your terminal:\n",
    "mv \"LSTM_train_eva (1).txt\" \"LSTM_train_eva (1).py\"\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
